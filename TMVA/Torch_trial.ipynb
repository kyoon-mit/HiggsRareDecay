{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94fb9b9-d445-463f-b0b2-d1bd713cfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c439953-4b2a-414d-9398-aac0a677000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import uproot\n",
    "\n",
    "# Decorrelation library\n",
    "import importlib\n",
    "disco = importlib.import_module('Disco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a3e73c-8550-423d-919e-b9239c4f0cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9082cbdc-f0e6-4c93-9892-47e312fa94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part 1. Load ROOT Data #######\n",
    "file_format = '/work/submit/kyoon/RareHiggs/data/cat_phi/cat_phi_VBF/test/test_mc{}_VBFcat_{}Cat.root'\n",
    "sgnmc = 1010\n",
    "channel = 'Phi'\n",
    "signal = uproot.open(file_format.format(sgnmc, channel))\n",
    "background1 = uproot.open(file_format.format(6, channel))\n",
    "background2 = uproot.open(file_format.format(7, channel))\n",
    "background3 = uproot.open(file_format.format(8, channel))\n",
    "background4 = uproot.open(file_format.format(9, channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f9ad31-6d75-4e2b-b3e3-c79215525610",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['HCandMass',\n",
    "             'HCandPT',\n",
    "             'goodMeson_iso',\n",
    "             'zepVar',\n",
    "             'w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc3f3ca-b105-4494-a3ab-0b3fdfe8a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "signal_df = signal['events'].arrays(variables, library='pd')\n",
    "background1_df = background1['events'].arrays(variables, library='pd')\n",
    "background2_df = background2['events'].arrays(variables, library='pd')\n",
    "background3_df = background3['events'].arrays(variables, library='pd') \n",
    "background4_df = background4['events'].arrays(variables, library='pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd832fa-c12f-44d3-94f3-7d58d5c7ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add truth values\n",
    "signal_df['y_true'] = 1\n",
    "background1_df['y_true'] = 0\n",
    "background2_df['y_true'] = 0\n",
    "background3_df['y_true'] = 0\n",
    "background4_df['y_true'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29f60e0-4f81-4fb5-b31f-2e20a0990087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine seperate dataframes into one object\n",
    "complete_df = pd.concat([signal_df,\n",
    "                         background1_df,\n",
    "                         background2_df,\n",
    "                         background3_df,\n",
    "                         background4_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d08a48-9bd3-4a9f-b1b7-f1281b5371b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle in random order\n",
    "complete_df = complete_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0578a37e-d4e8-4cca-878c-7ae226ce866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part 2. Prepare Data #######\n",
    "split_level = 0.7\n",
    "train_df = complete_df.sample(frac=split_level, random_state=137)\n",
    "test_df = complete_df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d0a83b-9164-4758-a05b-9a70a2a995cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['y_true', 'HCandMass', 'w']\n",
    "train_labels_df = pd.concat([train_df.pop(label) for label in labels], axis=1)\n",
    "test_labels_df = pd.concat([test_df.pop(label) for label in labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fdcf473-a6d1-49e0-b0b3-741d2034bfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85492, 3), (85492, 3), (36640, 3), (36640, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, train_labels_df.shape, test_df.shape, test_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d9ffc6-28d7-4b83-9b74-307b1804ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch-readable format\n",
    "train_X = torch.tensor(train_df.values).type(torch.float)\n",
    "train_Y = torch.tensor(train_labels_df.values).type(torch.float)\n",
    "test_X = torch.tensor(test_df.values).type(torch.float)\n",
    "test_Y = torch.tensor(test_labels_df.values).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b4e3b0-a8a1-4c64-bda3-48420412ade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = (train_Y[:,0] == 0).nonzero()\n",
    "len(train_Y[:,0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2931f9ce-2c01-4c99-a32b-20b82fe351c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize input\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe077e17-78aa-462f-851b-7bb69a560b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataloaders\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, X_data, Y_data, other_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "        self.other_data = other_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.Y_data[index],  self.other_data[index]\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.Y_data[index]\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "train_data = TrainData(torch.FloatTensor(train_X), \n",
    "                       torch.FloatTensor(train_Y[:,0]),\n",
    "                       torch.FloatTensor(train_Y[:,1:]))\n",
    "test_data = TestData(torch.FloatTensor(test_X),\n",
    "                     torch.FloatTensor(test_Y[:,0]))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7a8db2-1825-4f53-9999-ed2cacdcf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part N. Build Neural Network #######\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_shape, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(9, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805fe693-f3cb-42ac-8506-14a6aa573d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=9, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=9, out_features=9, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=9, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(3).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99435eb5-5326-4657-afa5-36cea240870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3c99f5c-93db-4f31-b489-d8f8c90456dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part N. Build Custom Loss #######\n",
    "def my_loss(y_pred, y_true, mass_tensor=[], weight_tensor=[], penalty_rate=0.1):\n",
    "    loss_term = nn.functional.binary_cross_entropy(y_pred, y_true)\n",
    "    bkg_indices = (y_true==0).nonzero()\n",
    "    if len(bkg_indices) <= 2:\n",
    "        return loss_term\n",
    "    else:\n",
    "        bkg_masses = mass_tensor[bkg_indices]\n",
    "        bkg_weights = weight_tensor\n",
    "        if torch.is_tensor(weight_tensor):\n",
    "            bkg_weights = weight_tensor[bkg_indices]\n",
    "        regularization_term = penalty_rate * disco.distance_corr(y_pred, mass_tensor, weight_tensor)\n",
    "        print(regularization_term, loss_term)\n",
    "        return loss_term + penalty_rate * regularization_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec1efd2b-8a5d-4bb4-aef9-f54b9a3d09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part N. Train Neural Network #######\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0d6904d-6cf1-4047-a395-cae63ce6b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "277fef8f-d1de-445c-8265-05c830156d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 001: | Loss: nan | Acc: 99.049\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 002: | Loss: nan | Acc: 99.059\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 003: | Loss: nan | Acc: 99.063\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 004: | Loss: nan | Acc: 99.052\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(nan, grad_fn=<MulBackward0>) tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 005: | Loss: nan | Acc: 99.056\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch_X, batch_Y, batch_other in train_loader:\n",
    "        batch_X, y_true, batch_other = batch_X.to(device), batch_Y.to(device), batch_other.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(batch_X)\n",
    "        y_pred = torch.full((len(batch_X), 1), .5, requires_grad=True)\n",
    "        \n",
    "        loss = my_loss(y_pred, y_true.unsqueeze(1),\n",
    "                       batch_other[:,0].unsqueeze(1),\n",
    "                       1, 1)\n",
    "                       # weight is 1 until I figure this out batch_other[:,1].unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_true.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a460d4bd-d54c-426d-a6fd-81c2e2b317b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Part N. Test Model #######\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in test_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        y_test_pred = model(batch_X)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag)\n",
    "        y_true_list.append(batch_Y)\n",
    "y_check_pred_list = torch.eq(torch.cat(y_pred_list), torch.cat(y_true_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f605988d-0e16-46e8-9168-7fce0da152b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_check_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "634c308c-62ac-4770-9e58-6f6494817c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=Net\n",
      "  (flatten): RecursiveScriptModule(original_name=Flatten)\n",
      "  (linear_relu_stack): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Linear)\n",
      "    (1): RecursiveScriptModule(original_name=ReLU)\n",
      "    (2): RecursiveScriptModule(original_name=Linear)\n",
      "    (3): RecursiveScriptModule(original_name=ReLU)\n",
      "    (4): RecursiveScriptModule(original_name=Linear)\n",
      "    (5): RecursiveScriptModule(original_name=Sigmoid)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = torch.jit.script(model)\n",
    "torch.jit.save(m, \"modelClassification.pt\")\n",
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rarehiggs",
   "language": "python",
   "name": "rarehiggs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
